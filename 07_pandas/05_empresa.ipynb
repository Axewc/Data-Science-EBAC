{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto empresa aliada: entregable 1\n",
    "\n",
    "Paso a paso:\n",
    "\n",
    "----\n",
    "## **Cargar las tablas de datos en Pandas:**\n",
    "\n",
    "Utiliza la función de Pandas para cargar cada tabla de datos desde el archivo csv o xlsx (DIM_CATEGORY, DIM_PRODUCT, DIM_SEGMENT, DIM_CALENDAR, FACT_SALES) en un DataFrame.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames cargados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --- 1. Cargar los Datos ---\n",
    "try:\n",
    "    df_dim_category = pd.read_csv('DIM_CATEGORY (2).csv')\n",
    "    df_dim_product = pd.read_excel('DIM_PRODUCT (1).xlsx')\n",
    "    df_dim_segment = pd.read_excel('DIM_SEGMENT (1).xlsx')\n",
    "    df_fact_sales = pd.read_csv('FACT_SALES (1).csv')\n",
    "    \n",
    "    # Crear una lista de DataFrames para iterar fácilmente (opcional)\n",
    "    dataframes = {\n",
    "        \"Category\": df_dim_category,\n",
    "        \"Product\": df_dim_product,\n",
    "        \"Segment\": df_dim_segment,\n",
    "        \"Sales\": df_fact_sales\n",
    "    }\n",
    "    print(\"DataFrames cargados exitosamente.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: No se encontró el archivo {e.filename}. Asegúrate de que los archivos estén en la ruta correcta.\")\n",
    "    # Salir o manejar el error como prefieras\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error al cargar los archivos: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a explorar las tablas.\n",
    "\n",
    "- 1. `DIM_CATEGORY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información general de DIM_CATEGORY:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID_CATEGORY  5 non-null      int64 \n",
      " 1   CATEGORY     5 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 212.0+ bytes\n",
      "\n",
      "Primeras filas DIM_CATEGORY:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_CATEGORY\n",
       "count     5.000000\n",
       "mean      3.000000\n",
       "std       1.581139\n",
       "min       1.000000\n",
       "25%       2.000000\n",
       "50%       3.000000\n",
       "75%       4.000000\n",
       "max       5.000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nInformación general de DIM_CATEGORY:\")\n",
    "df_dim_category.info()\n",
    "\n",
    "print(\"\\nPrimeras filas DIM_CATEGORY:\")\n",
    "df_dim_category.head()\n",
    "\n",
    "df_dim_category.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. `DIM_PRODUCT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Información general de DIM_PRODUCT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   MANUFACTURER      505 non-null    object\n",
      " 1   BRAND             505 non-null    object\n",
      " 2   ITEM              503 non-null    object\n",
      " 3   ITEM_DESCRIPTION  505 non-null    object\n",
      " 4   CATEGORY          505 non-null    int64 \n",
      " 5   FORMAT            505 non-null    object\n",
      " 6   ATTR1             499 non-null    object\n",
      " 7   ATTR2             505 non-null    object\n",
      " 8   ATTR3             499 non-null    object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 35.6+ KB\n",
      "\n",
      "Primeras filas de DIM_PRODUCT:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CATEGORY\n",
       "count     505.0\n",
       "mean        1.0\n",
       "std         0.0\n",
       "min         1.0\n",
       "25%         1.0\n",
       "50%         1.0\n",
       "75%         1.0\n",
       "max         1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n Información general de DIM_PRODUCT:\")\n",
    "df_dim_product.info()\n",
    "\n",
    "print(\"\\nPrimeras filas de DIM_PRODUCT:\")\n",
    "df_dim_product.head()\n",
    "\n",
    "df_dim_product.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3. `DIM_SEGMENT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información general de DIM_SEGMENT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   CATEGORY  53 non-null     int64 \n",
      " 1   ATTR1     53 non-null     object\n",
      " 2   ATTR2     53 non-null     object\n",
      " 3   ATTR3     52 non-null     object\n",
      " 4   FORMAT    53 non-null     object\n",
      " 5   SEGMENT   53 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.6+ KB\n",
      "None\n",
      "\n",
      "Primeras filas de DIM_SEGMENT:\n",
      "   CATEGORY  ATTR1  ATTR2      ATTR3   FORMAT SEGMENT\n",
      "0         1  CLORO  CLORO    BAMBINO  LIQUIDO  BLEACH\n",
      "1         1  CLORO  CLORO  GERMICIDA  LIQUIDO  BLEACH\n",
      "2         1  CLORO  CLORO   MASCOTAS  LIQUIDO  BLEACH\n",
      "3         1  CLORO  CLORO  MULTIUSOS      GEL  BLEACH\n",
      "4         1  CLORO  CLORO  MULTIUSOS  LIQUIDO  BLEACH\n",
      "       CATEGORY\n",
      "count      53.0\n",
      "mean        1.0\n",
      "std         0.0\n",
      "min         1.0\n",
      "25%         1.0\n",
      "50%         1.0\n",
      "75%         1.0\n",
      "max         1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInformación general de DIM_SEGMENT:\")\n",
    "print(df_dim_segment.info())\n",
    "\n",
    "print(\"\\nPrimeras filas de DIM_SEGMENT:\")\n",
    "print(df_dim_segment.head())\n",
    "\n",
    "print(df_dim_segment.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4. `FACT_SALES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras filas de FACT_SALES:\n",
      "    WEEK         ITEM_CODE  TOTAL_UNIT_SALES  TOTAL_VALUE_SALES  \\\n",
      "0  34-22  7501058792808BP2             0.006              0.139   \n",
      "1  34-22     7501058715883             0.487            116.519   \n",
      "2  34-22     7702626213774             1.391             68.453   \n",
      "3  34-22     7501058716422             0.022              1.481   \n",
      "4  34-22     7501058784353             2.037            182.839   \n",
      "\n",
      "   TOTAL_UNIT_AVG_WEEKLY_SALES              REGION  \n",
      "0                        1.000  TOTAL AUTOS AREA 5  \n",
      "1                        2.916  TOTAL AUTOS AREA 5  \n",
      "2                        5.171  TOTAL AUTOS AREA 5  \n",
      "3                        1.833  TOTAL AUTOS AREA 5  \n",
      "4                        5.375  TOTAL AUTOS AREA 5  \n",
      "\n",
      "Información general de FACT_SALES:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122002 entries, 0 to 122001\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   WEEK                         122002 non-null  object \n",
      " 1   ITEM_CODE                    122002 non-null  object \n",
      " 2   TOTAL_UNIT_SALES             122002 non-null  float64\n",
      " 3   TOTAL_VALUE_SALES            122002 non-null  float64\n",
      " 4   TOTAL_UNIT_AVG_WEEKLY_SALES  122002 non-null  float64\n",
      " 5   REGION                       122002 non-null  object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 5.6+ MB\n",
      "None\n",
      "       TOTAL_UNIT_SALES  TOTAL_VALUE_SALES  TOTAL_UNIT_AVG_WEEKLY_SALES\n",
      "count     122002.000000      122002.000000                122002.000000\n",
      "mean           3.211097          90.513761                    10.099904\n",
      "std           14.496009         350.236505                    22.650142\n",
      "min            0.000000           0.001000                     0.042000\n",
      "25%            0.063000           2.662000                     2.316000\n",
      "50%            0.367000          16.812000                     3.993500\n",
      "75%            1.520000          62.961500                     8.898000\n",
      "max          504.681000       12236.759000                   794.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrimeras filas de FACT_SALES:\")\n",
    "print(df_fact_sales.head())\n",
    "print(\"\\nInformación general de FACT_SALES:\")\n",
    "print(df_fact_sales.info())\n",
    "print(df_fact_sales.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## **Limpieza de Datos**\n",
    "\n",
    "- Corrige posibles inconsistencias en los datos, como errores tipográficos o formatos incorrectos.\n",
    "\n",
    "- Identifica y maneja valores nulos en cada DataFrame (si es que los hay)\n",
    "\n",
    "- Identifica si hay duplicados de los DataFrames y en caso de que los haya, eliminalos.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames cargados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Cargar los Datos ---\n",
    "try:\n",
    "    # Asegúrate de que las rutas sean correctas o los archivos estén en el mismo directorio\n",
    "    df_dim_category = pd.read_csv('DIM_CATEGORY (2).csv')\n",
    "    df_dim_product = pd.read_excel('DIM_PRODUCT (1).xlsx')\n",
    "    df_dim_segment = pd.read_excel('DIM_SEGMENT (1).xlsx')\n",
    "    df_fact_sales = pd.read_csv('FACT_SALES (1).csv')\n",
    "\n",
    "    print(\"DataFrames cargados exitosamente.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: No se encontró el archivo {e.filename}. Asegúrate de que los archivos estén en la ruta correcta.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error al cargar los archivos: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Limpieza df_dim_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpiando DataFrame: DIM_CATEGORY ---\n",
      "Tamaño original: (5, 2)\n",
      "Nulos originales:\n",
      "ID_CATEGORY    0\n",
      "CATEGORY       0\n",
      "dtype: int64\n",
      "Duplicados originales: 0\n",
      "Limpiando columna 'CATEGORY'...\n",
      "Nulos finales: 0\n",
      "Duplicados finales: 0\n",
      "Tamaño final: (5, 2)\n"
     ]
    }
   ],
   "source": [
    "# --- 2.1 Limpieza df_dim_category ---\n",
    "print(\"\\n--- Limpiando DataFrame: DIM_CATEGORY ---\")\n",
    "df = df_dim_category.copy() # Trabajar con una copia\n",
    "print(f\"Tamaño original: {df.shape}\")\n",
    "print(f\"Nulos originales:\\n{df.isnull().sum()}\")\n",
    "print(f\"Duplicados originales: {df.duplicated().sum()}\")\n",
    "\n",
    "# 2.1.1 Corregir Inconsistencias en 'CATEGORY'\n",
    "# - Eliminar caracteres '\\r\\n'\n",
    "# - Eliminar espacios extra al inicio/final\n",
    "# - Estandarizar a minúsculas (o mayúsculas si prefieres)\n",
    "if 'CATEGORY' in df.columns:\n",
    "    print(\"Limpiando columna 'CATEGORY'...\")\n",
    "    df['CATEGORY'] = df['CATEGORY'].str.replace('\\r\\n', '', regex=False) # Quitar saltos de línea\n",
    "    df['CATEGORY'] = df['CATEGORY'].str.strip() # Quitar espacios extra\n",
    "    df['CATEGORY'] = df['CATEGORY'].str.lower() # Convertir a minúsculas\n",
    "    # Podrías añadir más .replace() aquí si detectas otros errores específicos\n",
    "\n",
    "# 2.1.2 Manejo de Nulos (No hay según info, pero es buena práctica verificar)\n",
    "nulos_categoria = df.isnull().sum().sum()\n",
    "if nulos_categoria > 0:\n",
    "    print(f\"Advertencia: Se encontraron {nulos_categoria} nulos inesperados en DIM_CATEGORY.\")\n",
    "    # Decide cómo manejarlos si aparecen, ej: df.dropna(inplace=True)\n",
    "\n",
    "# 2.1.3 Manejo de Duplicados\n",
    "duplicados_antes = df.duplicated().sum()\n",
    "if duplicados_antes > 0:\n",
    "    # Considera si el duplicado debe basarse solo en 'ID_CATEGORY' o en ambas columnas\n",
    "    df.drop_duplicates(inplace=True) # Elimina duplicados basados en todas las columnas\n",
    "    print(f\"Se eliminaron {duplicados_antes} filas duplicadas.\")\n",
    "\n",
    "print(f\"Nulos finales: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicados finales: {df.duplicated().sum()}\")\n",
    "print(f\"Tamaño final: {df.shape}\")\n",
    "df_dim_category_clean = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 df_dim_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpiando DataFrame: DIM_PRODUCT ---\n",
      "Tamaño original: (505, 9)\n",
      "Nulos originales:\n",
      "MANUFACTURER        0\n",
      "BRAND               0\n",
      "ITEM                2\n",
      "ITEM_DESCRIPTION    0\n",
      "CATEGORY            0\n",
      "FORMAT              0\n",
      "ATTR1               6\n",
      "ATTR2               0\n",
      "ATTR3               6\n",
      "dtype: int64\n",
      "Duplicados originales: 0\n",
      "Limpiando columnas de texto...\n",
      "Manejando nulos...\n",
      "  - Se eliminaron 2 filas con 'ITEM' nulo.\n",
      "  - Columna 'ATTR1': 6 nulos imputados con 'desconocido'.\n",
      "  - Columna 'ATTR3': 6 nulos imputados con 'desconocido'.\n",
      "Nulos finales: 0\n",
      "Duplicados finales: 0\n",
      "Tamaño final: (503, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ax201\\AppData\\Local\\Temp\\ipykernel_16256\\4162783005.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('desconocido', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- 2.2 Limpieza df_dim_product ---\n",
    "print(\"\\n--- Limpiando DataFrame: DIM_PRODUCT ---\")\n",
    "df = df_dim_product.copy()\n",
    "print(f\"Tamaño original: {df.shape}\")\n",
    "print(f\"Nulos originales:\\n{df.isnull().sum()}\")\n",
    "print(f\"Duplicados originales: {df.duplicated().sum()}\")\n",
    "\n",
    "# 2.2.1 Corregir Inconsistencias y Tipos\n",
    "print(\"Limpiando columnas de texto...\")\n",
    "text_cols_product = ['MANUFACTURER', 'BRAND', 'ITEM', 'ITEM_DESCRIPTION', 'FORMAT', 'ATTR1', 'ATTR2', 'ATTR3']\n",
    "for col in text_cols_product:\n",
    "    if col in df.columns:\n",
    "        # Convertir a string por si acaso hay números interpretados como float/int\n",
    "        df[col] = df[col].astype(str) \n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col] = df[col].str.lower()\n",
    "        # Reemplazar 'nan' (texto) que puede resultar de la conversión a str de nulos\n",
    "        df[col] = df[col].replace('nan', np.nan) \n",
    "        # Estandarizar 'no definido' (observado en ATTR3)\n",
    "        df[col] = df[col].replace('no definido', 'desconocido') \n",
    "\n",
    "# La columna 'CATEGORY' es int64 y parece correcta (aunque todos son 1)\n",
    "# No requiere limpieza de formato/tipo por ahora.\n",
    "\n",
    "# 2.2.2 Manejo de Nulos\n",
    "print(\"Manejando nulos...\")\n",
    "# ITEM: Tiene 2 nulos. Un producto sin código es problemático. Eliminamos esas filas.\n",
    "nulos_item_antes = df['ITEM'].isnull().sum()\n",
    "if nulos_item_antes > 0:\n",
    "    df.dropna(subset=['ITEM'], inplace=True)\n",
    "    print(f\"  - Se eliminaron {nulos_item_antes} filas con 'ITEM' nulo.\")\n",
    "\n",
    "# ATTR1 y ATTR3: Tienen 6 nulos cada uno. Imputamos con 'desconocido'.\n",
    "cols_imputar_desc = ['ATTR1', 'ATTR3']\n",
    "for col in cols_imputar_desc:\n",
    "    if col in df.columns and df[col].isnull().any():\n",
    "        nulos_antes_col = df[col].isnull().sum()\n",
    "        df[col].fillna('desconocido', inplace=True)\n",
    "        print(f\"  - Columna '{col}': {nulos_antes_col} nulos imputados con 'desconocido'.\")\n",
    "\n",
    "# Verificar si quedan nulos inesperados\n",
    "nulos_producto = df.isnull().sum().sum()\n",
    "if nulos_producto > 0:\n",
    "    print(f\"Advertencia: Quedaron {nulos_producto} nulos inesperados en DIM_PRODUCT:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# 2.2.3 Manejo de Duplicados\n",
    "duplicados_antes = df.duplicated().sum()\n",
    "if duplicados_antes > 0:\n",
    "    # Decide si el duplicado se basa en todas las columnas o en una clave como 'ITEM'\n",
    "    # df.drop_duplicates(subset=['ITEM'], keep='first', inplace=True) # Opción por clave\n",
    "    df.drop_duplicates(inplace=True) # Opción por fila completa\n",
    "    print(f\"Se eliminaron {duplicados_antes} filas duplicadas.\")\n",
    "\n",
    "print(f\"Nulos finales: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicados finales: {df.duplicated().sum()}\")\n",
    "print(f\"Tamaño final: {df.shape}\")\n",
    "df_dim_product_clean = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Limpieza df_dim_segment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpiando DataFrame: DIM_SEGMENT ---\n",
      "Tamaño original: (53, 6)\n",
      "Nulos originales:\n",
      "CATEGORY    0\n",
      "ATTR1       0\n",
      "ATTR2       0\n",
      "ATTR3       1\n",
      "FORMAT      0\n",
      "SEGMENT     0\n",
      "dtype: int64\n",
      "Duplicados originales: 0\n",
      "Limpiando columnas de texto...\n",
      "Manejando nulos...\n",
      "  - Columna 'ATTR3': 1 nulos imputados con 'desconocido'.\n",
      "Nulos finales: 0\n",
      "Duplicados finales: 0\n",
      "Tamaño final: (53, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ax201\\AppData\\Local\\Temp\\ipykernel_16256\\3261469297.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ATTR3'].fillna('desconocido', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- 2.3 Limpieza df_dim_segment ---\n",
    "print(\"\\n--- Limpiando DataFrame: DIM_SEGMENT ---\")\n",
    "df = df_dim_segment.copy()\n",
    "print(f\"Tamaño original: {df.shape}\")\n",
    "print(f\"Nulos originales:\\n{df.isnull().sum()}\")\n",
    "print(f\"Duplicados originales: {df.duplicated().sum()}\")\n",
    "\n",
    "# 2.3.1 Corregir Inconsistencias\n",
    "print(\"Limpiando columnas de texto...\")\n",
    "text_cols_segment = ['ATTR1', 'ATTR2', 'ATTR3', 'FORMAT', 'SEGMENT']\n",
    "for col in text_cols_segment:\n",
    "     if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "        df[col] = df[col].replace('nan', np.nan) # Reemplazar 'nan' texto si aparece\n",
    "        # Podrías añadir más .replace() específicos aquí\n",
    "\n",
    "# La columna 'CATEGORY' es int64 y parece correcta (todos son 1)\n",
    "\n",
    "# 2.3.2 Manejo de Nulos\n",
    "print(\"Manejando nulos...\")\n",
    "# ATTR3: Tiene 1 nulo. Imputar con 'desconocido'.\n",
    "if 'ATTR3' in df.columns and df['ATTR3'].isnull().any():\n",
    "    nulos_attr3_antes = df['ATTR3'].isnull().sum()\n",
    "    df['ATTR3'].fillna('desconocido', inplace=True)\n",
    "    print(f\"  - Columna 'ATTR3': {nulos_attr3_antes} nulos imputados con 'desconocido'.\")\n",
    "\n",
    "# Verificar nulos restantes\n",
    "nulos_segment = df.isnull().sum().sum()\n",
    "if nulos_segment > 0:\n",
    "    print(f\"Advertencia: Quedaron {nulos_segment} nulos inesperados en DIM_SEGMENT:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# 2.3.3 Manejo de Duplicados\n",
    "duplicados_antes = df.duplicated().sum()\n",
    "if duplicados_antes > 0:\n",
    "    # Probablemente un duplicado aquí deba considerar todas las columnas relevantes\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Se eliminaron {duplicados_antes} filas duplicadas.\")\n",
    "\n",
    "print(f\"Nulos finales: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicados finales: {df.duplicated().sum()}\")\n",
    "print(f\"Tamaño final: {df.shape}\")\n",
    "df_dim_segment_clean = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Limpieza df_fact_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpiando DataFrame: FACT_SALES ---\n",
      "Tamaño original: (122002, 6)\n",
      "Nulos originales:\n",
      "WEEK                           0\n",
      "ITEM_CODE                      0\n",
      "TOTAL_UNIT_SALES               0\n",
      "TOTAL_VALUE_SALES              0\n",
      "TOTAL_UNIT_AVG_WEEKLY_SALES    0\n",
      "REGION                         0\n",
      "dtype: int64\n",
      "Duplicados originales: 0\n",
      "Limpiando columnas de texto...\n",
      "Nulos finales: 0\n",
      "Duplicados finales: 0\n",
      "Tamaño final: (122002, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Limpiando DataFrame: FACT_SALES ---\")\n",
    "df = df_fact_sales.copy()\n",
    "print(f\"Tamaño original: {df.shape}\")\n",
    "print(f\"Nulos originales:\\n{df.isnull().sum()}\")\n",
    "print(f\"Duplicados originales: {df.duplicated().sum()}\")\n",
    "\n",
    "# 2.4.1 Corregir Inconsistencias y Tipos\n",
    "print(\"Limpiando columnas de texto...\")\n",
    "# WEEK: Limpiar espacios, mantener formato original por ahora\n",
    "if 'WEEK' in df.columns:\n",
    "    df['WEEK'] = df['WEEK'].astype(str).str.strip()\n",
    "\n",
    "# ITEM_CODE: Limpiar espacios. NO convertir a minúsculas por si es sensible a mayúsculas/minúsculas.\n",
    "if 'ITEM_CODE' in df.columns:\n",
    "     df['ITEM_CODE'] = df['ITEM_CODE'].astype(str).str.strip()\n",
    "\n",
    "# REGION: Limpiar espacios y estandarizar a minúsculas\n",
    "if 'REGION' in df.columns:\n",
    "     df['REGION'] = df['REGION'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Columnas numéricas (float64) parecen correctas según .info() y .describe()\n",
    "# No se requiere conversión de tipo ni manejo de nulos según la info inicial.\n",
    "\n",
    "# 2.4.2 Manejo de Nulos (Verificación)\n",
    "nulos_sales = df.isnull().sum().sum()\n",
    "if nulos_sales > 0:\n",
    "    print(f\"Advertencia: Se encontraron {nulos_sales} nulos inesperados en FACT_SALES:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "    # Decide cómo manejarlos si aparecen. Podría ser eliminar la fila:\n",
    "    # df.dropna(inplace=True)\n",
    "\n",
    "# 2.4.3 Manejo de Duplicados\n",
    "duplicados_antes = df.duplicated().sum()\n",
    "if duplicados_antes > 0:\n",
    "    # Un registro de venta idéntico (misma semana, item, región, valores) suele ser un error\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Se eliminaron {duplicados_antes} filas duplicadas.\")\n",
    "\n",
    "print(f\"Nulos finales: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicados finales: {df.duplicated().sum()}\")\n",
    "print(f\"Tamaño final: {df.shape}\")\n",
    "df_fact_sales_clean = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificación Rápida Post-Limpieza General ---\n",
      "\n",
      "DataFrame Limpio: Category\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID_CATEGORY  5 non-null      int64 \n",
      " 1   CATEGORY     5 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 212.0+ bytes\n",
      "Nulos totales: 0\n",
      "Duplicados totales: 0\n",
      "Primeras filas:\n",
      "   ID_CATEGORY                    CATEGORY\n",
      "0            1  fabric treatment and sanit\n",
      "1            2                    air care\n",
      "2            3                lavavajillas\n",
      "3            4            mega superficies\n",
      "4            5         lavatory care & brc\n",
      "\n",
      "DataFrame Limpio: Product\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 503 entries, 0 to 504\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   MANUFACTURER      503 non-null    object\n",
      " 1   BRAND             503 non-null    object\n",
      " 2   ITEM              503 non-null    object\n",
      " 3   ITEM_DESCRIPTION  503 non-null    object\n",
      " 4   CATEGORY          503 non-null    int64 \n",
      " 5   FORMAT            503 non-null    object\n",
      " 6   ATTR1             503 non-null    object\n",
      " 7   ATTR2             503 non-null    object\n",
      " 8   ATTR3             503 non-null    object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 39.3+ KB\n",
      "Nulos totales: 0\n",
      "Duplicados totales: 0\n",
      "Primeras filas:\n",
      "  MANUFACTURER     BRAND           ITEM  \\\n",
      "0   inds. alen  cloralex  0000075000592   \n",
      "1   inds. alen  cloralex  0000075000608   \n",
      "2   inds. alen  cloralex  0000075000615   \n",
      "3   inds. alen  cloralex  0000075000622   \n",
      "4   inds. alen  cloralex  0000075000639   \n",
      "\n",
      "                                    ITEM_DESCRIPTION  CATEGORY   FORMAT  \\\n",
      "0  cloralex el rendidor bot.plast. 250ml nal. 000...         1  liquido   \n",
      "1  cloralex el rendidor bot.plast. 500ml nal. 000...         1  liquido   \n",
      "2  cloralex el rendidor bot.plast. 950ml nal. 000...         1  liquido   \n",
      "3  cloralex el rendidor bot.plast. 2000ml nal 000...         1  liquido   \n",
      "4  cloralex el rendidor bot.plast. 3750ml nal 000...         1  liquido   \n",
      "\n",
      "   ATTR1  ATTR2        ATTR3  \n",
      "0  cloro  cloro  desconocido  \n",
      "1  cloro  cloro  desconocido  \n",
      "2  cloro  cloro  desconocido  \n",
      "3  cloro  cloro  desconocido  \n",
      "4  cloro  cloro  desconocido  \n",
      "\n",
      "DataFrame Limpio: Segment\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   CATEGORY  53 non-null     int64 \n",
      " 1   ATTR1     53 non-null     object\n",
      " 2   ATTR2     53 non-null     object\n",
      " 3   ATTR3     53 non-null     object\n",
      " 4   FORMAT    53 non-null     object\n",
      " 5   SEGMENT   53 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.6+ KB\n",
      "Nulos totales: 0\n",
      "Duplicados totales: 0\n",
      "Primeras filas:\n",
      "   CATEGORY  ATTR1  ATTR2      ATTR3   FORMAT SEGMENT\n",
      "0         1  cloro  cloro    bambino  liquido  bleach\n",
      "1         1  cloro  cloro  germicida  liquido  bleach\n",
      "2         1  cloro  cloro   mascotas  liquido  bleach\n",
      "3         1  cloro  cloro  multiusos      gel  bleach\n",
      "4         1  cloro  cloro  multiusos  liquido  bleach\n",
      "\n",
      "DataFrame Limpio: Sales\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122002 entries, 0 to 122001\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   WEEK                         122002 non-null  object \n",
      " 1   ITEM_CODE                    122002 non-null  object \n",
      " 2   TOTAL_UNIT_SALES             122002 non-null  float64\n",
      " 3   TOTAL_VALUE_SALES            122002 non-null  float64\n",
      " 4   TOTAL_UNIT_AVG_WEEKLY_SALES  122002 non-null  float64\n",
      " 5   REGION                       122002 non-null  object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 5.6+ MB\n",
      "Nulos totales: 0\n",
      "Duplicados totales: 0\n",
      "Primeras filas:\n",
      "    WEEK         ITEM_CODE  TOTAL_UNIT_SALES  TOTAL_VALUE_SALES  \\\n",
      "0  34-22  7501058792808BP2             0.006              0.139   \n",
      "1  34-22     7501058715883             0.487            116.519   \n",
      "2  34-22     7702626213774             1.391             68.453   \n",
      "3  34-22     7501058716422             0.022              1.481   \n",
      "4  34-22     7501058784353             2.037            182.839   \n",
      "\n",
      "   TOTAL_UNIT_AVG_WEEKLY_SALES              REGION  \n",
      "0                        1.000  total autos area 5  \n",
      "1                        2.916  total autos area 5  \n",
      "2                        5.171  total autos area 5  \n",
      "3                        1.833  total autos area 5  \n",
      "4                        5.375  total autos area 5  \n"
     ]
    }
   ],
   "source": [
    "# --- Resumen Final y Verificación ---\n",
    "cleaned_dataframes = {\n",
    "    \"Category\": df_dim_category_clean,\n",
    "    \"Product\": df_dim_product_clean,\n",
    "    \"Segment\": df_dim_segment_clean,\n",
    "    \"Sales\": df_fact_sales_clean\n",
    "}\n",
    "\n",
    "print(\"\\n--- Verificación Rápida Post-Limpieza General ---\")\n",
    "for nombre, df_clean in cleaned_dataframes.items():\n",
    "    print(f\"\\nDataFrame Limpio: {nombre}\")\n",
    "    df_clean.info()\n",
    "    print(f\"Nulos totales: {df_clean.isnull().sum().sum()}\")\n",
    "    print(f\"Duplicados totales: {df_clean.duplicated().sum()}\")\n",
    "    print(f\"Primeras filas:\\n{df_clean.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar transformaciones necesarias:\n",
    "\n",
    "- Estandariza los formatos de las columnas, como las fechas o categorías, para asegurar la consistencia en todo el conjunto de datos.\n",
    "- Realiza cualquier transformación adicional requerida para preparar los datos para el análisis, como la creación de nuevas columnas calculadas o la agrupación de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames limpios encontrados en memoria. Procediendo a unir.\n"
     ]
    }
   ],
   "source": [
    "# --- Verificar que los DataFrames limpios existen ---\n",
    "# (Si no ejecutaste el código de limpieza justo antes, necesitarás cargarlos como arriba)\n",
    "try:\n",
    "    _ = df_dim_category_clean\n",
    "    _ = df_dim_product_clean\n",
    "    _ = df_dim_segment_clean\n",
    "    _ = df_fact_sales_clean\n",
    "    print(\"DataFrames limpios encontrados en memoria. Procediendo a unir.\")\n",
    "except NameError:\n",
    "    print(\"Error: Los DataFrames limpios no se encontraron en memoria.\")\n",
    "    print(\"Asegúrate de haber ejecutado el script de limpieza o de cargar los archivos limpios guardados.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unir Ventas con Productos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Uniendo Ventas con Productos ---\n",
      "Advertencia: 9193 registros de venta no encontraron un producto correspondiente en DIM_PRODUCT.\n",
      "Tamaño después de unir con productos: (122002, 14)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Unir Ventas con Productos ---\n",
    "print(\"\\n--- Uniendo Ventas con Productos ---\")\n",
    "# Clave izquierda: ITEM_CODE en df_fact_sales_clean\n",
    "# Clave derecha: ITEM en df_dim_product_clean\n",
    "# Usamos how='left' para mantener todos los registros de ventas,\n",
    "# incluso si algún producto no se encuentra en la tabla de dimensiones (resultará en NaN)\n",
    "df_merged = pd.merge(\n",
    "    df_fact_sales_clean,\n",
    "    df_dim_product_clean,\n",
    "    left_on='ITEM_CODE',\n",
    "    right_on='ITEM',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Verificar si hubo ventas sin producto correspondiente\n",
    "productos_no_encontrados = df_merged['ITEM'].isnull().sum()\n",
    "if productos_no_encontrados > 0:\n",
    "    print(f\"Advertencia: {productos_no_encontrados} registros de venta no encontraron un producto correspondiente en DIM_PRODUCT.\")\n",
    "    # Opcional: Investigar df_merged[df_merged['ITEM'].isnull()]['ITEM_CODE'].unique()\n",
    "\n",
    "# Limpieza post-merge: Eliminar la columna 'ITEM' redundante de la tabla de productos\n",
    "if 'ITEM' in df_merged.columns:\n",
    "    df_merged.drop(columns=['ITEM'], inplace=True)\n",
    "\n",
    "print(f\"Tamaño después de unir con productos: {df_merged.shape}\")\n",
    "# print(df_merged.head()) # Descomentar para ver las primeras filas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unir con Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Uniendo con Categorías ---\n",
      "Advertencia: 9193 registros no encontraron una categoría correspondiente en DIM_CATEGORY.\n",
      "Tamaño después de unir con categorías: (122002, 15)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Unir con Categorías ---\n",
    "print(\"\\n--- Uniendo con Categorías ---\")\n",
    "# Clave izquierda: CATEGORY (que vino de df_dim_product) en df_merged\n",
    "# Clave derecha: ID_CATEGORY en df_dim_category_clean\n",
    "# Renombrar columna CATEGORY de df_dim_category_clean para evitar conflicto\n",
    "df_dim_category_renamed = df_dim_category_clean.rename(columns={'CATEGORY': 'CATEGORY_NAME'})\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_dim_category_renamed,\n",
    "    left_on='CATEGORY',          # ID de categoría del producto\n",
    "    right_on='ID_CATEGORY',      # ID de categoría de la dimensión\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Verificar si hubo productos sin categoría correspondiente (poco probable si CATEGORY_ID=1 siempre)\n",
    "categorias_no_encontradas = df_merged['ID_CATEGORY'].isnull().sum()\n",
    "if categorias_no_encontradas > 0:\n",
    "     print(f\"Advertencia: {categorias_no_encontradas} registros no encontraron una categoría correspondiente en DIM_CATEGORY.\")\n",
    "\n",
    "# Limpieza post-merge: Eliminar la columna 'ID_CATEGORY' redundante y quizás 'CATEGORY' (el ID) si solo quieres el nombre\n",
    "if 'ID_CATEGORY' in df_merged.columns:\n",
    "    df_merged.drop(columns=['ID_CATEGORY'], inplace=True)\n",
    "# Opcional: si no necesitas el ID numérico de categoría, puedes eliminarlo también\n",
    "# if 'CATEGORY' in df_merged.columns:\n",
    "#    df_merged.drop(columns=['CATEGORY'], inplace=True)\n",
    "\n",
    "print(f\"Tamaño después de unir con categorías: {df_merged.shape}\")\n",
    "# print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unir con Segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Uniendo con Segmentos ---\n",
      "Info: 12565 registros no encontraron un segmento correspondiente directo en DIM_SEGMENT (pueden ser combinaciones no listadas).\n",
      "Tamaño después de unir con segmentos: (122002, 16)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Unir con Segmentos ---\n",
    "print(\"\\n--- Uniendo con Segmentos ---\")\n",
    "# Clave: Múltiples columnas que deben coincidir en ambas tablas.\n",
    "# Estas columnas vinieron de df_dim_product y deben coincidir con las de df_dim_segment\n",
    "segment_key_columns = ['CATEGORY', 'ATTR1', 'ATTR2', 'ATTR3', 'FORMAT']\n",
    "\n",
    "# Verificar que las columnas clave existen en ambos DataFrames antes de unir\n",
    "missing_keys_left = [col for col in segment_key_columns if col not in df_merged.columns]\n",
    "missing_keys_right = [col for col in segment_key_columns if col not in df_dim_segment_clean.columns]\n",
    "\n",
    "if missing_keys_left or missing_keys_right:\n",
    "     print(\"Error: Faltan columnas clave para la unión con segmentos.\")\n",
    "     if missing_keys_left: print(f\"  - Faltan en tabla izquierda (df_merged): {missing_keys_left}\")\n",
    "     if missing_keys_right: print(f\"  - Faltan en tabla derecha (df_dim_segment_clean): {missing_keys_right}\")\n",
    "else:\n",
    "    df_merged = pd.merge(\n",
    "        df_merged,\n",
    "        df_dim_segment_clean,\n",
    "        on=segment_key_columns, # Usar 'on' cuando los nombres de columna coinciden\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Verificar si hubo productos/atributos sin segmento correspondiente\n",
    "    segmentos_no_encontrados = df_merged['SEGMENT'].isnull().sum()\n",
    "    # Es normal que haya algunos NaN aquí si no todas las combinaciones ATTR1-3/FORMAT tienen un segmento definido\n",
    "    print(f\"Info: {segmentos_no_encontrados} registros no encontraron un segmento correspondiente directo en DIM_SEGMENT (pueden ser combinaciones no listadas).\")\n",
    "     \n",
    "    print(f\"Tamaño después de unir con segmentos: {df_merged.shape}\")\n",
    "    # print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Proceso de Unión Completado ---\n",
      "Información del DataFrame final consolidado:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122002 entries, 0 to 122001\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   WEEK                         122002 non-null  object \n",
      " 1   ITEM_CODE                    122002 non-null  object \n",
      " 2   TOTAL_UNIT_SALES             122002 non-null  float64\n",
      " 3   TOTAL_VALUE_SALES            122002 non-null  float64\n",
      " 4   TOTAL_UNIT_AVG_WEEKLY_SALES  122002 non-null  float64\n",
      " 5   REGION                       122002 non-null  object \n",
      " 6   MANUFACTURER                 112809 non-null  object \n",
      " 7   BRAND                        112809 non-null  object \n",
      " 8   ITEM_DESCRIPTION             112809 non-null  object \n",
      " 9   CATEGORY                     112809 non-null  float64\n",
      " 10  FORMAT                       112809 non-null  object \n",
      " 11  ATTR1                        112809 non-null  object \n",
      " 12  ATTR2                        112809 non-null  object \n",
      " 13  ATTR3                        112809 non-null  object \n",
      " 14  CATEGORY_NAME                112809 non-null  object \n",
      " 15  SEGMENT                      109437 non-null  object \n",
      "dtypes: float64(4), object(12)\n",
      "memory usage: 14.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- DataFrame Final Consolidado ---\n",
    "print(\"\\n--- Proceso de Unión Completado ---\")\n",
    "df_final_consolidado = df_merged.copy() # Crear una copia final\n",
    "\n",
    "print(\"Información del DataFrame final consolidado:\")\n",
    "df_final_consolidado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificación de Nulos en el DataFrame final:\n",
      "MANUFACTURER         9193\n",
      "BRAND                9193\n",
      "ITEM_DESCRIPTION     9193\n",
      "CATEGORY             9193\n",
      "FORMAT               9193\n",
      "ATTR1                9193\n",
      "ATTR2                9193\n",
      "ATTR3                9193\n",
      "CATEGORY_NAME        9193\n",
      "SEGMENT             12565\n",
      "dtype: int64\n",
      "\n",
      "Primeras filas del DataFrame final consolidado:\n",
      "    WEEK         ITEM_CODE  TOTAL_UNIT_SALES  TOTAL_VALUE_SALES  \\\n",
      "0  34-22  7501058792808BP2             0.006              0.139   \n",
      "1  34-22     7501058715883             0.487            116.519   \n",
      "2  34-22     7702626213774             1.391             68.453   \n",
      "3  34-22     7501058716422             0.022              1.481   \n",
      "4  34-22     7501058784353             2.037            182.839   \n",
      "\n",
      "   TOTAL_UNIT_AVG_WEEKLY_SALES              REGION MANUFACTURER   BRAND  \\\n",
      "0                        1.000  total autos area 5          NaN     NaN   \n",
      "1                        2.916  total autos area 5      reckitt  vanish   \n",
      "2                        5.171  total autos area 5      reckitt  vanish   \n",
      "3                        1.833  total autos area 5      reckitt  vanish   \n",
      "4                        5.375  total autos area 5      reckitt  vanish   \n",
      "\n",
      "                                    ITEM_DESCRIPTION  CATEGORY FORMAT  \\\n",
      "0                                                NaN       NaN    NaN   \n",
      "1  vanish oxi action gold quitamanchas bolsa 1.8k...       1.0  polvo   \n",
      "2  vanish oxi action rosa quitamanchas doypack 24...       1.0  polvo   \n",
      "3  vanish oxi action gold quitamancha ahorro del ...       1.0  polvo   \n",
      "4  vanish intelligence polvo bote 450 gr nal 7501...       1.0  polvo   \n",
      "\n",
      "         ATTR1             ATTR2 ATTR3               CATEGORY_NAME SEGMENT  \n",
      "0          NaN               NaN   NaN                         NaN     NaN  \n",
      "1  safe bleach  fabric treatment  rosa  fabric treatment and sanit  powder  \n",
      "2  safe bleach  fabric treatment  rosa  fabric treatment and sanit  powder  \n",
      "3  safe bleach  fabric treatment  rosa  fabric treatment and sanit  powder  \n",
      "4  safe bleach  fabric treatment  rosa  fabric treatment and sanit  powder  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificación de Nulos en el DataFrame final:\")\n",
    "null_counts = df_final_consolidado.isnull().sum()\n",
    "print(null_counts[null_counts > 0]) # Mostrar solo columnas con nulos\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame final consolidado:\")\n",
    "print(df_final_consolidado.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## **Guardar el conjunto de datos consolidado:**\n",
    "\n",
    "- Guarda el DataFrame consolidado en un nuevo archivo CSV o Excel para su uso posterior en el análisis.\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame final guardado.\n"
     ]
    }
   ],
   "source": [
    "# --- Guardar el DataFrame consolidado ---\n",
    "df_final_consolidado.to_csv('ventas_finales.csv', index=False)\n",
    "df_final_consolidado.to_excel('ventas_finales.xlsx', index=False)\n",
    "print(\"\\nDataFrame final guardado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
